{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import timm  # For Vision Transformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models\n",
    "\n",
    "#CNN Model:\n",
    "\n",
    "cnn_model = torchvision.models.resnet50(pretrained=True)\n",
    "cnn_model.fc = nn.Linear(cnn_model.fc.in_features, 10)  # STL-10 has 10 classes\n",
    "cnn_model = cnn_model.to(device)\n",
    "\n",
    "\n",
    "#ViT Model:\n",
    "vit_model = timm.create_model(\"vit_small_patch16_224\", pretrained=True, num_classes=10)\n",
    "vit_model = vit_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base Dataset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # upscale CIFAR-10 (32x32) to 96x96 so both models work fine\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225))  # ImageNet normalization\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset  = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=64, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch images shape: torch.Size([64, 3, 224, 224])\n",
      "Batch labels shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(train_loader))\n",
    "print(\"Batch images shape:\", X.shape)\n",
    "print(\"Batch labels shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model functions\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    return (y_true == y_pred).sum().item() / len(y_true) * 100\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer_cnn = optim.Adam(cnn_model.parameters(), lr=1e-4)\n",
    "optimizer_vit = optim.AdamW(vit_model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_step(model, data_loader, loss_fn, optimizer, accuracy_fn, device=device):\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    # Create a progress bar for the DataLoader\n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\")\n",
    "\n",
    "    for X, y in progress_bar:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # Loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Accuracy\n",
    "        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the progress bar with current loss and accuracy\n",
    "        progress_bar.set_postfix(loss=loss.item(), accuracy=accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)))\n",
    "\n",
    "    return train_loss / len(data_loader), train_acc / len(data_loader)\n",
    "\n",
    "def test_step(model, data_loader, loss_fn, accuracy_fn, device=device):\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        # Create a progress bar for the DataLoader\n",
    "        progress_bar = tqdm(data_loader, desc=\"Testing\")\n",
    "        for X, y in progress_bar:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Loss + accuracy\n",
    "            loss = loss_fn(y_pred, y).item()\n",
    "            test_loss += loss\n",
    "            test_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "            # Update the progress bar with current loss and accuracy\n",
    "            progress_bar.set_postfix(loss=loss, accuracy=accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)))\n",
    "\n",
    "    return test_loss / len(data_loader), test_acc / len(data_loader)\n",
    "\n",
    "# def train_step(model, data_loader, loss_fn, optimizer, accuracy_fn, device=device):\n",
    "#     model.train()\n",
    "#     train_loss, train_acc = 0, 0\n",
    "\n",
    "#     for X, y in data_loader:\n",
    "#         X, y = X.to(device), y.to(device)\n",
    "\n",
    "#         # Forward pass\n",
    "#         y_pred = model(X)\n",
    "\n",
    "#         # Loss\n",
    "#         loss = loss_fn(y_pred, y)\n",
    "#         train_loss += loss.item()\n",
    "\n",
    "#         # Accuracy\n",
    "#         train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "#         # Backpropagation\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         progress_bar.set_postfix(loss=loss.item(), accuracy=accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)))\n",
    "\n",
    "#     return train_loss / len(data_loader), train_acc / len(data_loader)\n",
    "\n",
    "\n",
    "# def test_step(model, data_loader, loss_fn, accuracy_fn, device=device):\n",
    "#     model.eval()\n",
    "#     test_loss, test_acc = 0, 0\n",
    "\n",
    "#     with torch.inference_mode():\n",
    "#         for X, y in data_loader:\n",
    "#             X, y = X.to(device), y.to(device)\n",
    "#             y_pred = model(X)\n",
    "\n",
    "#             # Loss + accuracy\n",
    "#             test_loss += loss_fn(y_pred, y).item()\n",
    "#             test_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "#     return test_loss / len(data_loader), test_acc / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [30:34<00:00,  2.35s/it, accuracy=93.8, loss=0.136] \n",
      "Testing: 100%|██████████| 157/157 [00:37<00:00,  4.20it/s, accuracy=93.8, loss=0.368] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CNN] Train Loss: 0.2925, Train Acc: 90.32%\n",
      "[CNN] Test  Loss: 0.1955, Test  Acc: 93.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 782/782 [12:41<00:00,  1.03it/s, accuracy=100, loss=0.00133]\n",
      "Testing: 100%|██████████| 157/157 [00:52<00:00,  2.98it/s, accuracy=93.8, loss=0.0774]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ViT] Train Loss: 0.1450, Train Acc: 95.32%\n",
      "[ViT] Test  Loss: 0.1024, Test  Acc: 96.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Simple test\n",
    "\n",
    "train_loss, train_acc = train_step(cnn_model, train_loader, loss_fn, optimizer_cnn, accuracy_fn)\n",
    "test_loss, test_acc   = test_step(cnn_model, test_loader, loss_fn, accuracy_fn)\n",
    "\n",
    "print(f\"[CNN] Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "print(f\"[CNN] Test  Loss: {test_loss:.4f}, Test  Acc: {test_acc:.2f}%\")\n",
    "\n",
    "train_loss, train_acc = train_step(vit_model, train_loader, loss_fn, optimizer_vit, accuracy_fn)\n",
    "test_loss, test_acc   = test_step(vit_model, test_loader, loss_fn, accuracy_fn)\n",
    "\n",
    "print(f\"[ViT] Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "print(f\"[ViT] Test  Loss: {test_loss:.4f}, Test  Acc: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 157/157 [01:03<00:00,  2.47it/s, accuracy=93.8, loss=0.368] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CNN] Test  Loss: 0.1955, Test  Acc: 93.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 157/157 [00:56<00:00,  2.80it/s, accuracy=93.8, loss=0.0774]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ViT] Test  Loss: 0.1024, Test  Acc: 96.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc   = test_step(cnn_model, test_loader, loss_fn, accuracy_fn)\n",
    "print(f\"[CNN] Test  Loss: {test_loss:.4f}, Test  Acc: {test_acc:.2f}%\")\n",
    "test_loss, test_acc   = test_step(vit_model, test_loader, loss_fn, accuracy_fn)\n",
    "print(f\"[ViT] Test  Loss: {test_loss:.4f}, Test  Acc: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models...\n",
      "Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#Define file paths for saving\n",
    "cnn_path = \"resnet50_cifar10_new.pth\"\n",
    "vit_path = \"vit_small_cifar10_new.pth\"\n",
    "\n",
    "print(\"Saving models...\")\n",
    "\n",
    "# Save the CNN model's state_dict\n",
    "torch.save(cnn_model.state_dict(), cnn_path)\n",
    "\n",
    "# Save the ViT model's state_dict\n",
    "torch.save(vit_model.state_dict(), vit_path)\n",
    "\n",
    "print(\"Models saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
